{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66270de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LEGAL CASE SUMMARIZATION USING LEXRANK + BART\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK data (run once)\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5339ad77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Case Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The State Of Tamil Nadu vs The Governor Of Tam...</td>\n",
       "      <td>https://indiankanoon.org/docfragment/82729634/...</td>\n",
       "      <td>Take notes as you read a judgment using ourVir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Independent Sugar Corporation Limited vs Giris...</td>\n",
       "      <td>https://indiankanoon.org/docfragment/117249167...</td>\n",
       "      <td>Take notes as you read a judgment using ourVir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piramal Capital And Housing Finance ... vs 63 ...</td>\n",
       "      <td>https://indiankanoon.org/docfragment/190999006...</td>\n",
       "      <td>Take notes as you read a judgment using ourVir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In Re Recruitment Of Visually Impaired ... vs ...</td>\n",
       "      <td>https://indiankanoon.org/docfragment/158218833...</td>\n",
       "      <td>Take notes as you read a judgment using ourVir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Union Of India vs Future Gaming Solutions P.Lt...</td>\n",
       "      <td>https://indiankanoon.org/docfragment/117744026...</td>\n",
       "      <td>Take notes as you read a judgment using ourVir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Case Title  \\\n",
       "0  The State Of Tamil Nadu vs The Governor Of Tam...   \n",
       "1  Independent Sugar Corporation Limited vs Giris...   \n",
       "2  Piramal Capital And Housing Finance ... vs 63 ...   \n",
       "3  In Re Recruitment Of Visually Impaired ... vs ...   \n",
       "4  Union Of India vs Future Gaming Solutions P.Lt...   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://indiankanoon.org/docfragment/82729634/...   \n",
       "1  https://indiankanoon.org/docfragment/117249167...   \n",
       "2  https://indiankanoon.org/docfragment/190999006...   \n",
       "3  https://indiankanoon.org/docfragment/158218833...   \n",
       "4  https://indiankanoon.org/docfragment/117744026...   \n",
       "\n",
       "                                        Case Content  \n",
       "0  Take notes as you read a judgment using ourVir...  \n",
       "1  Take notes as you read a judgment using ourVir...  \n",
       "2  Take notes as you read a judgment using ourVir...  \n",
       "3  Take notes as you read a judgment using ourVir...  \n",
       "4  Take notes as you read a judgment using ourVir...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: LOAD YOUR DATA\n",
    "# ============================================================================\n",
    "\n",
    "df = pd.read_csv('710cases.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cea66b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset loaded: 710 cases\n",
      "üìè Average case length: 7186 words\n"
     ]
    }
   ],
   "source": [
    "print(f\"üìä Dataset loaded: {len(df)} cases\")\n",
    "print(f\"üìè Average case length: {df['Case Content'].apply(lambda x: len(str(x).split())).mean():.0f} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa472d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Preprocessing functions ready!\n"
     ]
    }
   ],
   "source": [
    "# # ============================================================================\n",
    "# # STEP 3: TEXT PREPROCESSING FOR LEGAL DOCUMENTS\n",
    "# # ============================================================================\n",
    "\n",
    "# def preprocess_legal_text(text):\n",
    "#     \"\"\"\n",
    "#     Clean and preprocess legal case text\n",
    "#     \"\"\"\n",
    "#     if not isinstance(text, str):\n",
    "#         return \"\"\n",
    "    \n",
    "#     # Remove extra whitespace\n",
    "#     text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "#     text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    \n",
    "#     # Remove citation patterns like (2020) or [2020]\n",
    "#     text = re.sub(r'\\([^)]*\\d{4}[^)]*\\)', '', text)\n",
    "#     text = re.sub(r'\\[[^\\]]*\\d{4}[^\\]]*\\]', '', text)\n",
    "    \n",
    "#     # Remove case numbers and reference patterns\n",
    "#     text = re.sub(r'AIR\\s+\\d{4}', '', text)\n",
    "#     text = re.sub(r'SCC\\s+\\d+', '', text)\n",
    "#     text = re.sub(r'CrLJ\\s+\\d+', '', text)\n",
    "    \n",
    "#     # Remove excessive legal jargon markers\n",
    "#     text = re.sub(r'\\s+vs?\\s+', ' vs ', text, flags=re.IGNORECASE)\n",
    "    \n",
    "#     return text.strip()\n",
    "\n",
    "# print(\"‚úÖ Preprocessing functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e8d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LexRank extractive summarizer ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: EXTRACTIVE SUMMARIZATION USING LEXRANK\n",
    "# ============================================================================\n",
    "\n",
    "def extract_key_sentences(text, sentence_count=15):\n",
    "    \n",
    "    try:\n",
    "        # Preprocess\n",
    "        clean_text = preprocess_legal_text(text)\n",
    "        \n",
    "        # LexRank works best with at least some content\n",
    "        if len(clean_text.split()) < 100:\n",
    "            return clean_text\n",
    "        \n",
    "        # Calculate sentence count based on document length\n",
    "        word_count = len(clean_text.split())\n",
    "        if word_count > 50000:\n",
    "            sentence_count = 200 \n",
    "        elif word_count > 20000:\n",
    "            sentence_count = 150 \n",
    "        elif word_count > 10000:\n",
    "            sentence_count = 100  \n",
    "        elif word_count > 5000:\n",
    "            sentence_count = 700  \n",
    "        elif word_count > 2000:\n",
    "            sentence_count = 50\n",
    "        else:\n",
    "            sentence_count = 30  \n",
    "        \n",
    "        # Create parser\n",
    "        parser = PlaintextParser.from_string(clean_text, Tokenizer(\"english\"))\n",
    "        \n",
    "        # Use LexRank summarizer\n",
    "        stemmer = Stemmer(\"english\")\n",
    "        summarizer = LexRankSummarizer(stemmer)\n",
    "        summarizer.stop_words = get_stop_words(\"english\")\n",
    "        \n",
    "        # Get important sentences\n",
    "        summary_sentences = summarizer(parser.document, sentence_count)\n",
    "        \n",
    "        \n",
    "        summary_sentences_with_pos = []\n",
    "        for sentence in summary_sentences:\n",
    "            original_text = str(sentence)\n",
    "            # Find position in original document\n",
    "            pos = clean_text.find(original_text)\n",
    "            summary_sentences_with_pos.append((pos, original_text))\n",
    "\n",
    "        # Sort by position\n",
    "        summary_sentences_with_pos.sort(key=lambda x: x[0])\n",
    "\n",
    "        # Combine in original order\n",
    "        extracted_text = \" \".join([sent for pos, sent in summary_sentences_with_pos])\n",
    "        \n",
    "        return extracted_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è LexRank extraction error: {e}\")\n",
    "        # Fallback: return first 2000 words\n",
    "        words = clean_text.split()[:2000]\n",
    "        return \" \".join(words)\n",
    "\n",
    "print(\"‚úÖ LexRank extractive summarizer ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f824619c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Loading BART model...\n",
      "üñ•Ô∏è Using device: cpu\n",
      "‚úÖ BART model loaded successfully!\n",
      "‚úÖ BART abstractive summarizer ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: ABSTRACTIVE SUMMARIZATION USING BART\n",
    "# ============================================================================\n",
    "\n",
    "# Load BART model (this will download ~1.6GB first time)\n",
    "print(\"\\nüì• Loading BART model...\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üñ•Ô∏è Using device: {device}\")\n",
    "\n",
    "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to(device)\n",
    "\n",
    "print(\"‚úÖ BART model loaded successfully!\")\n",
    "\n",
    "def generate_abstractive_summary(text, max_length=700, min_length=200):\n",
    "    \n",
    "    try:\n",
    "        inputs = bart_tokenizer(\n",
    "            text,\n",
    "            max_length=1024, \n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            summary_ids = bart_model.generate(\n",
    "                inputs.input_ids,\n",
    "                max_length=max_length,\n",
    "                min_length=min_length,\n",
    "                length_penalty=2.0,\n",
    "                num_beams=4,\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=3 \n",
    "            )\n",
    "        \n",
    "        summary = bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è BART generation error: {e}\")\n",
    "        return \"Summary generation failed.\"\n",
    "\n",
    "print(\"‚úÖ BART abstractive summarizer ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb3552d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete hybrid pipeline ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: COMPLETE PIPELINE - HYBRID SUMMARIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def summarize_legal_case_hybrid(case_text, max_summary_length=500):\n",
    "    \"\"\"\n",
    "    Complete hybrid summarization pipeline:\n",
    "    1. Extract key sentences using LexRank (extractive)\n",
    "    2. Generate clean summary using BART (abstractive)\n",
    "    \n",
    "    Args:\n",
    "        case_text: Full legal case content\n",
    "        max_summary_length: Target summary length\n",
    "    \n",
    "    Returns:\n",
    "        Final summary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Extract important content using LexRank\n",
    "    print(\"  üîç Extracting key sentences with LexRank...\")\n",
    "    extracted_content = extract_key_sentences(case_text)\n",
    "    \n",
    "    # Step 2: Generate clean summary using BART\n",
    "    print(\"  ‚úçÔ∏è Generating summary with BART...\")\n",
    "    final_summary = generate_abstractive_summary(\n",
    "        extracted_content,\n",
    "        max_length=700,\n",
    "        min_length=300\n",
    "    )\n",
    "    \n",
    "    return final_summary\n",
    "\n",
    "print(\"‚úÖ Complete hybrid pipeline ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1644123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ TESTING ON SAMPLE CASES\n",
      "\n",
      "\n",
      "üìÑ Case 1: Zahoor Ahmad Rather vs Sheikh Imtiyaz Ahmad on 5 December, 2...\n",
      "   Original length: 2917 words\n",
      "  üîç Extracting key sentences with LexRank...\n",
      "  ‚úçÔ∏è Generating summary with BART...\n",
      "   Summary length: 244 words\n",
      "   ‚úÖ Summary: State Service Selection Board (SSSB) for filling up the posts of Technician- allowed the writ petitions on the ground that it was not open to the SSSB to noted that a candidate possessing a Diploma ‚Äì ...\n",
      "\n",
      "üìÑ Case 2: The State Of Bihar vs Devendra Sharma on 17 October, 2019...\n",
      "   Original length: 4757 words\n",
      "  üîç Extracting key sentences with LexRank...\n",
      "  ‚úçÔ∏è Generating summary with BART...\n",
      "   Summary length: 245 words\n",
      "   ‚úÖ Summary: Case, the employees were put in following three categories: 5 for short, ‚ÄòState Committee‚Äô7October 6, 2009 whereby, the report submitted by three. The issue of any procedural irregularity for a findin...\n",
      "\n",
      "üìÑ Case 3: Kamal Singh vs State Of Haryana on 29 July, 2010...\n",
      "   Original length: 2330 words\n",
      "  üîç Extracting key sentences with LexRank...\n",
      "  ‚úçÔ∏è Generating summary with BART...\n",
      "   Summary length: 262 words\n",
      "   ‚úÖ Summary: Ten persons in all, Kamal Singh the appellant of Kamal. Singh, Maya wife of Attar Singh and Urmila KamalSingh's house stick and also warned Manti not to tie the cattle at other accused climbed up to t...\n",
      "\n",
      "üìÑ Case 4: The State Of Bihar And Anr vs Amit Kumar @ Bachcha Rai on 20...\n",
      "   Original length: 99 words\n",
      "  üîç Extracting key sentences with LexRank...\n",
      "  ‚úçÔ∏è Generating summary with BART...\n",
      "   Summary length: 242 words\n",
      "   ‚úÖ Summary: This criminal appeal is filed by State of Bihar against the final judgment passed in Criminal Miscellaneous No. 53391 of 2016. The High Court of Judicature at Patna has passed the following order: Nim...\n",
      "\n",
      "üìÑ Case 5: Khoday Distilleries Ltd. (Now Khoday ... vs Sri Mahadeshwara...\n",
      "   Original length: 1224 words\n",
      "  üîç Extracting key sentences with LexRank...\n",
      "  ‚úçÔ∏è Generating summary with BART...\n",
      "   Summary length: 244 words\n",
      "   ‚úÖ Summary: Review petition has been dismissed by the High Court vide Though in this case situation was not where review petition was 5  16 6  8 7 2018 (11) Scale 141Civil Appeal arising out of SLP (C) No.490 of ...\n",
      "üìä SAMPLE RESULTS\n",
      "                                          Case Title  \\\n",
      "0  Zahoor Ahmad Rather vs Sheikh Imtiyaz Ahmad on...   \n",
      "1  The State Of Bihar vs Devendra Sharma on 17 Oc...   \n",
      "2   Kamal Singh vs State Of Haryana on 29 July, 2010   \n",
      "3  The State Of Bihar And Anr vs Amit Kumar @ Bac...   \n",
      "4  Khoday Distilleries Ltd. (Now Khoday ... vs Sr...   \n",
      "\n",
      "                                             Summary  \n",
      "0  State Service Selection Board (SSSB) for filli...  \n",
      "1  Case, the employees were put in following thre...  \n",
      "2  Ten persons in all, Kamal Singh the appellant ...  \n",
      "3  This criminal appeal is filed by State of Biha...  \n",
      "4  Review petition has been dismissed by the High...  \n",
      "\n",
      "üíæ Sample results saved to 'sample_cases_summarized_hybrid.csv'\n",
      "‚úÖ TESTING COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: TEST ON SAMPLE CASES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüß™ TESTING ON SAMPLE CASES\\n\")\n",
    "\n",
    "sample_df = df.sample(n=5, random_state=42).reset_index(drop=True)\n",
    "\n",
    "summaries = []\n",
    "\n",
    "for idx, row in sample_df.iterrows():\n",
    "    case_title = row['Case Title']\n",
    "    case_text = row['Case Content']\n",
    "    \n",
    "    print(f\"\\nüìÑ Case {idx+1}: {case_title[:60]}...\")\n",
    "    print(f\"   Original length: {len(str(case_text).split())} words\")\n",
    "    \n",
    "    summary = summarize_legal_case_hybrid(case_text, max_summary_length=400)\n",
    "    summaries.append(summary)\n",
    "    \n",
    "    print(f\"   Summary length: {len(summary.split())} words\")\n",
    "    print(f\"   ‚úÖ Summary: {summary[:200]}...\")\n",
    "\n",
    "sample_df['Summary'] = summaries\n",
    "\n",
    "# Display results\n",
    "print(\"üìä SAMPLE RESULTS\")\n",
    "print(sample_df[['Case Title', 'Summary']].head())\n",
    "\n",
    "# Save sample results\n",
    "sample_df.to_csv('sample_cases_summarized_hybrid.csv', index=False)\n",
    "print(\"\\nüíæ Sample results saved to 'sample_cases_summarized_hybrid.csv'\")\n",
    "\n",
    "print(\"‚úÖ TESTING COMPLETE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
